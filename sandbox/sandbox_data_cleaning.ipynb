{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../developer'))\n",
    "\n",
    "from config import MOCK_DATA, CODE\n",
    "from developer.utilities import read_yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data and make it into long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, specs, renaming_specs):\n",
    "\n",
    "    # Initial Cleaning\n",
    "    df = df.drop([0, 1])\n",
    "    \n",
    "    df = df.replace(renaming_specs['utility'])\n",
    "    for category in list(renaming_specs['attributes'].keys()):\n",
    "        df = df.replace(renaming_specs['attributes'][category])\n",
    "\n",
    "    # Keep Variables\n",
    "    variable_specs = specs[\"variables\"]\n",
    "    groups_of_vars = variable_specs.keys()\n",
    "    vars_to_keep=[]\n",
    "    for group in groups_of_vars:\n",
    "        vars_to_keep += variable_specs[group][\"names\"]\n",
    "\n",
    "    df = df[vars_to_keep]\n",
    "\n",
    "    # Transform types\n",
    "    for group in groups_of_vars:\n",
    "        if variable_specs[group][\"type\"] == 'categorical':\n",
    "            df[variable_specs[group][\"names\"]] = df[variable_specs[group][\"names\"]].astype('category')\n",
    "\n",
    "        elif variable_specs[group][\"type\"] == 'numerical':\n",
    "            df[variable_specs[group][\"names\"]] = df[variable_specs[group][\"names\"]].astype('int')\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    df['ID'] = range(1, len(df) + 1)\n",
    "    #df = df.set_index(\"ID\")\n",
    "\n",
    "    # Add inconsistency indicator\n",
    "    df = _inconsistency(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _inconsistency(df):\n",
    "    \"\"\"Looks for inconsistency between preferred package and  choices and likert rating\"\"\"\n",
    "    \n",
    "    for round in range(1,7):\n",
    "        df[f'likert_choice_{round}_A'] = df[f'likert_{round}_1'] >= df[f'likert_{round}_2']\n",
    "        df[f'likert_choice_{round}_B'] = df[f'likert_{round}_1'] <= df[f'likert_{round}_2']\n",
    "    \n",
    "        df[f'inconsistency_{round}'] = ((df[f'likert_choice_{round}_A'] == 0) & (df[f'choice_set_{round}'] == 'A')) | ((df[f'likert_choice_{round}_B'] == 0) & (df[f'choice_set_{round}'] == 'B'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_long(df, renaming_specs):\n",
    "    \"\"\"Transforms the wide-format survey daya into a long-format DataFrame with repeated measures.\n",
    "\n",
    "    This function takes the wide format from the raw survey data, where each row represents a participant\n",
    "    and each column corresponds different settings for the different choice sets across multiple rounds. \n",
    "    It converts the DataFrame into a long format, with each row representing an individual choice round, \n",
    "    associated with the participant and the round.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame in wide format with participant data and multiple rounds.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A long-format DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    long_df = pd.DataFrame()\n",
    "    for round in range(1,7):\n",
    "        df_temp = df[['ID',\n",
    "                      f'round_{round}_att_1_a', \n",
    "                      f'round_{round}_att_1_b',\n",
    "                      f'round_{round}_att_2_a', \n",
    "                      f'round_{round}_att_2_b', \n",
    "                      f'round_{round}_att_3_a', \n",
    "                      f'round_{round}_att_3_b', \n",
    "                      f'round_{round}_att_4_a', \n",
    "                      f'round_{round}_att_4_b', \n",
    "                      f'round_{round}_att_5_a', \n",
    "                      f'round_{round}_att_5_b', \n",
    "#                      f'round_{round}_att_6_a', \n",
    "#                      f'round_{round}_att_6_b',  \n",
    "                      f'choice_set_{round}', \n",
    "                      f'likert_{round}_1', \n",
    "                      f'likert_{round}_2',\n",
    "                      f'inconsistency_{round}']].copy()\n",
    "        df_temp['round'] = round\n",
    "        df_temp = df_temp.rename(columns={\n",
    "            f'round_{round}_att_1_a' : renaming_specs[\"new_names\"][0], \n",
    "            f'round_{round}_att_1_b' : renaming_specs[\"new_names\"][1],\n",
    "            f'round_{round}_att_2_a' : renaming_specs[\"new_names\"][2], \n",
    "            f'round_{round}_att_2_b' : renaming_specs[\"new_names\"][3], \n",
    "            f'round_{round}_att_3_a' : renaming_specs[\"new_names\"][4], \n",
    "            f'round_{round}_att_3_b' : renaming_specs[\"new_names\"][5], \n",
    "            f'round_{round}_att_4_a' : renaming_specs[\"new_names\"][6], \n",
    "            f'round_{round}_att_4_b' : renaming_specs[\"new_names\"][7], \n",
    "            f'round_{round}_att_5_a' : renaming_specs[\"new_names\"][8], \n",
    "            f'round_{round}_att_5_b' : renaming_specs[\"new_names\"][9], \n",
    "#            f'round_{round}_att_6_a' : renaming_specs[\"new_names\"][10], \n",
    "#            f'round_{round}_att_6_b' : renaming_specs[\"new_names\"][11], \n",
    "            f'choice_set_{round}' : 'choice', \n",
    "            f'likert_{round}_1' : 'utility_A',\n",
    "            f'likert_{round}_2' : 'utility_B',\n",
    "            f'inconsistency_{round}' :  'inconsistent'\n",
    "        })\n",
    "        long_df = pd.concat([long_df, df_temp])\n",
    "\n",
    "    first_columns = ['ID', 'round']\n",
    "    all_cols = long_df.columns\n",
    "\n",
    "    new_order = first_columns + [c for c in all_cols if c not in first_columns]\n",
    "\n",
    "    long_df = long_df[new_order]\n",
    "    long_df = long_df.set_index(['ID', 'round'])\n",
    "    long_df = long_df.sort_index()\n",
    "    \n",
    "    return long_df\n",
    "\n",
    "def make_dummy(df, renaming_specs):\n",
    "    # Create dummy variables for each attribute level\n",
    "    attribute_cols = renaming_specs['new_names']\n",
    "    df_with_dummies = pd.get_dummies(df, columns=attribute_cols)\n",
    "\n",
    "    return df_with_dummies\n",
    "\n",
    "def ready_for_regression(df_with_dummies):\n",
    "    A_columns = [c for c in list(df_with_dummies.columns) if \"_A\" in c] + [\"inconsistent\"]\n",
    "    B_columns = [c for c in list(df_with_dummies.columns) if \"_B\" in c] + [\"inconsistent\"]\n",
    "    new_columns = [col.replace( '_A', '') for col in A_columns]\n",
    "\n",
    "    df_A = df_with_dummies[A_columns].copy()\n",
    "    df_A.columns = new_columns\n",
    "    df_A[\"package\"] = \"A\"\n",
    "    df_B = df_with_dummies[B_columns].copy()\n",
    "    df_B.columns = new_columns\n",
    "    df_B[\"package\"] = \"B\"\n",
    "    total = pd.concat([df_A, df_B])\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjoint = pd.read_csv(MOCK_DATA / \"raw_data_mock.csv\", encoding='cp1252')\n",
    "specs = read_yaml(CODE / \"data_management\" / \"specs.yaml\")\n",
    "renaming_specs = read_yaml(CODE / \"data_management\" / \"renaming_replacing.yaml\")\n",
    "\n",
    "conjoint = clean_data(conjoint, specs, renaming_specs)\n",
    "conjoint_long = make_long(conjoint,renaming_specs)\n",
    "conjoint_dummy = make_dummy(conjoint_long, renaming_specs)\n",
    "conjoint_reg = ready_for_regression(conjoint_dummy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency data\n",
    "\n",
    "I want to produce frequencies of each attribute, such that we can see how often they showed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute_level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PhaseOut</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StatusQuo</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop&amp;Maintain</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop&amp;Reduce</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighInvestment&amp;Int</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HighInvestment&amp;Int&amp;Consideration</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowInvestment</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowInvestment&amp;LowConsideration</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnergyAccess</th>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HealthEdu</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowPrices</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NothingSoc</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfers</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateJobs</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EarlyPension</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobGuarantee</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NothingEco</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrain</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CentralGov</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CivilNGO</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnergySector</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabourUnion</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocalGov</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Researchers</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  frequency\n",
       "Attribute_level                            \n",
       "PhaseOut                               0.23\n",
       "StatusQuo                              0.23\n",
       "Stop&Maintain                          0.25\n",
       "Stop&Reduce                            0.29\n",
       "HighInvestment&Int                     0.24\n",
       "HighInvestment&Int&Consideration       0.26\n",
       "LowInvestment                          0.27\n",
       "LowInvestment&LowConsideration         0.23\n",
       "EnergyAccess                           0.21\n",
       "HealthEdu                              0.24\n",
       "LowPrices                              0.15\n",
       "NothingSoc                             0.22\n",
       "Transfers                              0.17\n",
       "CreateJobs                             0.23\n",
       "EarlyPension                           0.15\n",
       "JobGuarantee                           0.20\n",
       "NothingEco                             0.25\n",
       "Retrain                                0.16\n",
       "CentralGov                             0.12\n",
       "CivilNGO                               0.17\n",
       "EnergySector                           0.15\n",
       "LabourUnion                            0.14\n",
       "LocalGov                               0.15\n",
       "Media                                  0.13\n",
       "Researchers                            0.14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conjoint_dummy.columns.str.startswith('att')\n",
    "def frequencies(conjoint_reg):\n",
    "    \n",
    "    frequency_table =  {}\n",
    "    groups = ['att_1', 'att_2','att_3', 'att_4', 'att_5'] #add 6\n",
    "    for group in groups:\n",
    "        total = sum(dict(conjoint_reg.filter(like=group).sum()).values())\n",
    "        frequency_table[group] = {key.replace(f'{group}_', '') : (value / total).round(2) for key, value in dict(conjoint_reg.filter(like=group).sum()).items()}\n",
    "    frequency_table = pd.DataFrame(frequency_table).sum(axis=1)\n",
    "    frequency_table = pd.DataFrame(frequency_table, columns=[\"frequency\"])\n",
    "\n",
    "    frequency_table = frequency_table.rename_axis(\"Attribute_level\")\n",
    "    return frequency_table\n",
    "\n",
    "frequencies(conjoint_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conjoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
