{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../developer'))\n",
    "\n",
    "from config import MOCK_DATA, CODE, OUT, IN\n",
    "from developer.utilities import read_yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data and make it into long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, specs, renaming_specs):\n",
    "    \"\"\"Cleans and preprocesses the input DataFrame according to provided specifications.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame containing raw data to be cleaned.\n",
    "        specs (dict): A dictionary containing specifications for data cleaning and preprocessing.\n",
    "        renaming_specs (dict): A dictionary containing specifications for renaming attribute and utility names.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A cleaned and preprocessed DataFrame following the specified operations.\n",
    "\n",
    "    See Also:\n",
    "        _inconsistency: An internal function used to compute the inconsistency indicator.\n",
    "\n",
    "    \"\"\"\n",
    "    # Initial Cleaning\n",
    "    df = df.drop([0, 1])\n",
    "    \n",
    "    df = df.replace(renaming_specs['utility'])\n",
    "    df = df.replace(renaming_specs['treatment'])\n",
    "    df = df.replace(renaming_specs['trust'])\n",
    "    df = df.replace(renaming_specs['locationFilter'])\n",
    "    for category in list(renaming_specs['attributes'].keys()):\n",
    "        if category == 'soc_distributive':\n",
    "            columns_to_replace = df.filter(like='att_2').columns\n",
    "            \n",
    "            # Replace values in selected columns\n",
    "            df[columns_to_replace] = df[columns_to_replace].replace(renaming_specs['attributes'][category])\n",
    "\n",
    "        else:    \n",
    "            df = df.replace(renaming_specs['attributes'][category])\n",
    "\n",
    "    # Keep Variables\n",
    "    variable_specs = specs[\"variables\"]\n",
    "    groups_of_vars = variable_specs.keys()\n",
    "    vars_to_keep=[]\n",
    "    for group in groups_of_vars:\n",
    "        vars_to_keep += variable_specs[group][\"names\"]\n",
    "\n",
    "    df = df[vars_to_keep]\n",
    "\n",
    "    # Transform types\n",
    "    for group in groups_of_vars:\n",
    "        if variable_specs[group][\"type\"] == 'categorical':\n",
    "            df[variable_specs[group][\"names\"]] = df[variable_specs[group][\"names\"]].astype('category')\n",
    "\n",
    "        elif variable_specs[group][\"type\"] == 'numerical':\n",
    "            df[variable_specs[group][\"names\"]] = df[variable_specs[group][\"names\"]].astype('int')\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    df['ID'] = range(1, len(df) + 1)\n",
    "    #df = df.set_index(\"ID\")\n",
    "\n",
    "    # Add inconsistency indicator\n",
    "    df = _inconsistency(df)\n",
    "    df = _trust_ID(df)\n",
    "    df = _coal_region(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _trust_ID(df):\n",
    "    df[['trust_in_governement_1', 'trust_in_governement_2', 'trust_in_governement_3']] = df[['trust_in_governement_1', 'trust_in_governement_2', 'trust_in_governement_3']].astype(int)\n",
    "    df['trust_average'] = df[['trust_in_governement_1', 'trust_in_governement_2', 'trust_in_governement_3']].mean(axis=1)\n",
    "    df['trust_ID'] = df['trust_average'] >= 5\n",
    "\n",
    "    return df\n",
    "\n",
    "def _inconsistency(df):\n",
    "    \"\"\"Looks for inconsistency between preferred package and  choices and likert rating\"\"\"\n",
    "    \n",
    "    for round in range(1,7):\n",
    "        df[f'likert_choice_{round}_A'] = df[f'likert_{round}_1'] >= df[f'likert_{round}_2']\n",
    "        df[f'likert_choice_{round}_B'] = df[f'likert_{round}_1'] <= df[f'likert_{round}_2']\n",
    "    \n",
    "        df[f'inconsistency_{round}'] = ((df[f'likert_choice_{round}_A'] == 0) & (df[f'choice_set_{round}'] == 'A')) | ((df[f'likert_choice_{round}_B'] == 0) & (df[f'choice_set_{round}'] == 'B'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _coal_region(df):\n",
    "    df['coal_region'] = (df['locationFilter'] == 1).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def make_long(df, renaming_specs):\n",
    "    \"\"\"Transforms the wide-format survey daya into a long-format DataFrame with repeated measures.\n",
    "\n",
    "    This function takes the wide format from the raw survey data, where each row represents a participant\n",
    "    and each column corresponds different settings for the different choice sets across multiple rounds. \n",
    "    It converts the DataFrame into a long format, with each row representing an individual choice round, \n",
    "    associated with the participant and the round.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input DataFrame in wide format with participant data and multiple rounds.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A long-format DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    long_df = pd.DataFrame()\n",
    "    for round in range(1,7):\n",
    "        df_temp = df[['ID',\n",
    "                      'treatment_status',\n",
    "                      'trust_in_governement_1',\n",
    "                      'trust_in_governement_2',\n",
    "                      'trust_in_governement_3',\n",
    "                      'trust_average',\n",
    "                      'trust_ID',\n",
    "                      'coal_region',\n",
    "                      f'round_{round}_att_1_a', \n",
    "                      f'round_{round}_att_1_b',\n",
    "                      f'round_{round}_att_2_a', \n",
    "                      f'round_{round}_att_2_b', \n",
    "                      f'round_{round}_att_3_a', \n",
    "                      f'round_{round}_att_3_b', \n",
    "                      f'round_{round}_att_4_a', \n",
    "                      f'round_{round}_att_4_b', \n",
    "                      f'round_{round}_att_5_a', \n",
    "                      f'round_{round}_att_5_b', \n",
    "                      f'round_{round}_att_6_a', \n",
    "                      f'round_{round}_att_6_b',  \n",
    "                      f'choice_set_{round}', \n",
    "                      f'likert_{round}_1', \n",
    "                      f'likert_{round}_2',\n",
    "                      f'inconsistency_{round}']].copy()\n",
    "        df_temp['round'] = round\n",
    "        df_temp = df_temp.rename(columns={\n",
    "            f'round_{round}_att_1_a' : renaming_specs[\"new_names\"][0], \n",
    "            f'round_{round}_att_1_b' : renaming_specs[\"new_names\"][1],\n",
    "            f'round_{round}_att_2_a' : renaming_specs[\"new_names\"][2], \n",
    "            f'round_{round}_att_2_b' : renaming_specs[\"new_names\"][3], \n",
    "            f'round_{round}_att_3_a' : renaming_specs[\"new_names\"][4], \n",
    "            f'round_{round}_att_3_b' : renaming_specs[\"new_names\"][5], \n",
    "            f'round_{round}_att_4_a' : renaming_specs[\"new_names\"][6], \n",
    "            f'round_{round}_att_4_b' : renaming_specs[\"new_names\"][7], \n",
    "            f'round_{round}_att_5_a' : renaming_specs[\"new_names\"][8], \n",
    "            f'round_{round}_att_5_b' : renaming_specs[\"new_names\"][9], \n",
    "            f'round_{round}_att_6_a' : renaming_specs[\"new_names\"][10], \n",
    "            f'round_{round}_att_6_b' : renaming_specs[\"new_names\"][11], \n",
    "            f'choice_set_{round}' : 'choice', \n",
    "            f'likert_{round}_1' : 'utility_A',\n",
    "            f'likert_{round}_2' : 'utility_B',\n",
    "            f'inconsistency_{round}' :  'inconsistent'\n",
    "        })\n",
    "        long_df = pd.concat([long_df, df_temp])\n",
    "\n",
    "    first_columns = ['ID', 'round']\n",
    "    all_cols = long_df.columns\n",
    "\n",
    "    new_order = first_columns + [c for c in all_cols if c not in first_columns]\n",
    "\n",
    "    long_df = long_df[new_order]\n",
    "    long_df = long_df.set_index(['ID', 'round'])\n",
    "    long_df = long_df.sort_index()\n",
    "    \n",
    "    return long_df\n",
    "\n",
    "def make_dummy(df, renaming_specs):\n",
    "    # Create dummy variables for each attribute level\n",
    "    attribute_cols = renaming_specs['new_names']\n",
    "    df_with_dummies = pd.get_dummies(df, columns=attribute_cols)\n",
    "\n",
    "    return df_with_dummies\n",
    "\n",
    "def make_ready_for_regression(df_with_dummies):\n",
    "    A_columns = [c for c in list(df_with_dummies.columns) if \"_A\" in c] + [\"inconsistent\", \"treatment_status\", \"trust_ID\", \"coal_region\"]\n",
    "    B_columns = [c for c in list(df_with_dummies.columns) if \"_B\" in c] + [\"inconsistent\", \"treatment_status\", \"trust_ID\", \"coal_region\"]\n",
    "    new_columns = [col.replace( '_A', '') for col in A_columns]\n",
    "\n",
    "    df_A = df_with_dummies[A_columns].copy()\n",
    "    df_A.columns = new_columns\n",
    "    df_A[\"package\"] = \"A\"\n",
    "    df_B = df_with_dummies[B_columns].copy()\n",
    "    df_B.columns = new_columns\n",
    "    df_B[\"package\"] = \"B\"\n",
    "    total = pd.concat([df_A, df_B])\n",
    "    \n",
    "    total = total.reset_index()\n",
    "    total = total.set_index(['ID', 'round', 'package'])\n",
    "\n",
    "    total = _set_support_dummy(total)\n",
    "    total = standardize(total, 'utility')\n",
    "\n",
    "    return total\n",
    "\n",
    "def make_long_descriptive(df):\n",
    "    df = df.copy()\n",
    "    A_columns = [c for c in list(df.columns) if \"_A\" in c] + [\"inconsistent\", \"treatment_status\", \"trust_ID\", \"coal_region\"]\n",
    "    B_columns = [c for c in list(df.columns) if \"_A\" in c] + [\"inconsistent\", \"treatment_status\", \"trust_ID\", \"coal_region\"]\n",
    "    new_columns = [col.replace( '_A', '') for col in A_columns]\n",
    "\n",
    "    df_A = df[A_columns].copy()\n",
    "    df_A.columns = new_columns\n",
    "    df_A[\"package\"] = \"A\"\n",
    "    df_B = df[B_columns].copy()\n",
    "    df_B.columns = new_columns\n",
    "    df_B[\"package\"] = \"B\"\n",
    "    df = pd.concat([df_A, df_B])\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index(['ID', 'round', 'package'])\n",
    "\n",
    "    df = _set_support_dummy(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _set_support_dummy(df):\n",
    "\n",
    "    df['support'] = df['utility'] >= 5\n",
    "    df['unsupport'] = df['utility'] <= 3\n",
    "\n",
    "    return df\n",
    "\n",
    "def frequencies(conjoint_reg):\n",
    "    \n",
    "    frequency_table =  {}\n",
    "    groups = ['att_1', 'att_2','att_3', 'att_4', 'att_5', 'att_6'] #add 6\n",
    "    for group in groups:\n",
    "        total = sum(dict(conjoint_reg.filter(like=group).sum()).values())\n",
    "        frequency_table[group] = {key.replace(f'{group}_', '') : (value / total).round(2) for key, value in dict(conjoint_reg.filter(like=group).sum()).items()}\n",
    "    frequency_table = pd.DataFrame(frequency_table).sum(axis=1)\n",
    "    frequency_table = pd.DataFrame(frequency_table, columns=[\"frequency\"])\n",
    "\n",
    "    frequency_table = frequency_table.rename_axis(\"Attribute_level\")\n",
    "    return frequency_table\n",
    "\n",
    "def standardize(df, column):\n",
    "    df[f'{column}_standardized'] = (df[column] - df[column].mean()) / df[column].std()\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjoint = pd.read_csv(IN / \"first_sample.csv\", encoding='utf8')\n",
    "specs = read_yaml(CODE / \"data_management\" / \"specs.yaml\")\n",
    "renaming_specs = read_yaml(CODE / \"data_management\" / \"renaming_replacing.yaml\")\n",
    "\n",
    "conjoint = clean_data(conjoint, specs, renaming_specs)\n",
    "conjoint_long = make_long(conjoint,renaming_specs)\n",
    "conjoint_long_descript = make_long_descriptive(conjoint_long)\n",
    "conjoint_dummy = make_dummy(conjoint_long, renaming_specs)\n",
    "conjoint_reg = make_ready_for_regression(conjoint_dummy)\n",
    "\n",
    "#inspect=conjoint.filter(like='attribute_').iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(OUT / \"data\" / \"data_regression.csv\", encoding='utf8')\n",
    "\n",
    "#liste = (df['q_main_energy_ov'] == '1') & (df['q_coal_sub_ov'] == '1') & (df['q_elec_sub_ov'] == '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-09-05 16:31:48', '4f02ac93-c1de-e511-af6d-9829c1bc8c0a', 'Hydropower']\n",
      "['2023-09-06 14:37:27', '4f4a356a-58d4-2fc9-af94-016160c1fef3', 'Coal']\n",
      "['2023-09-06 14:44:35', '3bf0890e-142c-97c6-15f0-bddb7935d294', 'Hydropower']\n",
      "['2023-09-06 17:49:49', 'fb4c8228-5de0-dd12-84d6-b667b3b3c9c1', 'Coal']\n",
      "['2023-09-07 06:24:45', 'e0987d51-52fa-7a4c-40af-49b349ffb9c8', 'Coal']\n",
      "['2023-09-07 12:46:16', '334ff4fe-685b-5df8-7f03-c0643bf07165', 'Nuclear Power']\n",
      "['2023-09-07 12:55:10', 'ea900222-d10d-b404-a0df-36bbb86f0dba', 'Coal']\n",
      "['2023-09-07 16:04:53', 'c68cee54-a829-85b8-85a9-daa7fa80bbcc', 'Coal']\n",
      "['2023-09-07 16:09:32', '4b1bfd81-9acb-3c51-147c-c930eba9b11d', 'Coal']\n",
      "['2023-09-07 16:36:37', '6ebcb461-8797-6904-b49c-8097fbc89ffb', 'Coal']\n",
      "['2023-09-08 18:51:51', '5c094ffd-6b48-6762-a800-7b2277a06861', 'Nuclear Power']\n",
      "['2023-09-08 18:54:07', 'c1ca39be-e7de-1bf3-6b43-0de11c809d25', 'Nuclear Power']\n",
      "['2023-09-08 19:10:09', '9ef04fcd-ab42-93e1-5630-7bdbe01dc955', 'Gas']\n",
      "['2023-09-08 19:12:43', '9ef04fcd-ab42-93e1-5630-7bdbe01dc955', 'Gas']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(IN / \"main_sample.csv\", encoding='utf8')\n",
    "\n",
    "df = df.drop([0, 1])\n",
    "\n",
    "duplicate_rows = df[df.duplicated(subset=['IPAddress', 'LocationLatitude', 'LocationLongitude'], keep=False)]\n",
    "#duplicate_rows = duplicate_rows[['IPAddress', 'LocationLatitude', 'LocationLongitude', 'uid']]\n",
    "#duplicate_rows = df[df.duplicated(subset=['uid'], keep=False)]\n",
    "\n",
    "inspect = duplicate_rows[['RecordedDate', 'uid', 'q_main_energy_ov', 'IPAddress', 'LocationLatitude', 'LocationLongitude','genderFilter','ageFilter']]\n",
    "for index, row in duplicate_rows[['RecordedDate', 'uid', 'q_main_energy_ov']].iterrows():\n",
    "    print(row.tolist())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency data and checks\n",
    "\n",
    "Checks: How often do each variable show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conjoint_dummy.columns.str.startswith('att')\n",
    "def frequencies(conjoint_reg):\n",
    "    \n",
    "    frequency_table =  {}\n",
    "    groups = ['att_1', 'att_2','att_3', 'att_4', 'att_5'] #add 6\n",
    "    for group in groups:\n",
    "        total = sum(dict(conjoint_reg.filter(like=group).sum()).values())\n",
    "        frequency_table[group] = {key.replace(f'{group}_', '') : (value / total).round(2) for key, value in dict(conjoint_reg.filter(like=group).sum()).items()}\n",
    "    frequency_table = pd.DataFrame(frequency_table).sum(axis=1)\n",
    "    frequency_table = pd.DataFrame(frequency_table, columns=[\"frequency\"])\n",
    "\n",
    "    frequency_table = frequency_table.rename_axis(\"Attribute_level\")\n",
    "    return frequency_table\n",
    "\n",
    "frequencies(conjoint_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute_level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eliminate&amp;UseAllOther</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eliminate&amp;UseRenewables</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reduce&amp;IncreaseAllOther</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reduce&amp;IncreaseRenewables</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnergyAccess</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InsureWorkers</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowPrices</th>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NothingSoc</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IdentityCoalRegions</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IndustryCoalRegions</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NothingEco</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkersCoalRegion</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gov&amp;Businesses</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gov&amp;CivilSociety</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gov&amp;LaborUnions</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gov&amp;LocalGov</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gov&amp;Researchers</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GovAlone</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin&amp;TechSupport</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinSupportOnly</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoInterference</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechSupportOnly</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           frequency\n",
       "Attribute_level                     \n",
       "Eliminate&UseAllOther           0.25\n",
       "Eliminate&UseRenewables         0.24\n",
       "Reduce&IncreaseAllOther         0.26\n",
       "Reduce&IncreaseRenewables       0.25\n",
       "EnergyAccess                    0.25\n",
       "InsureWorkers                   0.22\n",
       "LowPrices                       0.28\n",
       "NothingSoc                      0.26\n",
       "IdentityCoalRegions             0.24\n",
       "IndustryCoalRegions             0.26\n",
       "NothingEco                      0.25\n",
       "WorkersCoalRegion               0.25\n",
       "Gov&Businesses                  0.18\n",
       "Gov&CivilSociety                0.16\n",
       "Gov&LaborUnions                 0.15\n",
       "Gov&LocalGov                    0.18\n",
       "Gov&Researchers                 0.16\n",
       "GovAlone                        0.18\n",
       "Fin&TechSupport                 0.22\n",
       "FinSupportOnly                  0.25\n",
       "NoInterference                  0.23\n",
       "TechSupportOnly                 0.29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies(conjoint_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfigure_factory\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mff\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m clean_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(OUT \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata_clean.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m clean_data[\u001b[39m'\u001b[39m\u001b[39mDurationMin\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m clean_data[\u001b[39m'\u001b[39m\u001b[39mDuration (in seconds)\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m60\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39m# Calculate the average and median\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "\n",
    "clean_data = pd.read_csv(OUT / \"data\" / \"data_clean.csv\")\n",
    "\n",
    "clean_data['DurationMin'] = clean_data['Duration (in seconds)'] / 60\n",
    "\n",
    "# Calculate the average and median\n",
    "average_duration = clean_data['DurationMin'].mean()\n",
    "median_duration = clean_data['DurationMin'].median()\n",
    "\n",
    "fig = ff.create_distplot([clean_data['DurationMin']], ['DurationMin'], show_curve=True, show_rug=False, bin_size=2.0)\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=average_duration,\n",
    "    x1=average_duration,\n",
    "    y0=0,\n",
    "    y1=1,\n",
    "    xref='x',\n",
    "    yref='paper',\n",
    "    line=dict(color='red', width=2, dash='dash'),\n",
    "    name=f'Average: {average_duration:.2f}'\n",
    ")\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=median_duration,\n",
    "    x1=median_duration,\n",
    "    y0=0,\n",
    "    y1=1,\n",
    "    xref='x',\n",
    "    yref='paper',\n",
    "    line=dict(color='green', width=2, dash='dash'),\n",
    "    name=f'Median: {median_duration:.2f}'\n",
    ")\n",
    "\n",
    "# Add labels for average and median values\n",
    "fig.add_annotation(\n",
    "    x=average_duration,\n",
    "    y=0.9,\n",
    "    xref='x',\n",
    "    yref='paper',\n",
    "    text=f'Average: {average_duration:.2f}',\n",
    "    showarrow=True,\n",
    "    arrowhead=4,\n",
    "    ax=0,\n",
    "    ay=-40\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=median_duration,\n",
    "    y=0.9,\n",
    "    xref='x',\n",
    "    yref='paper',\n",
    "    text=f'Median: {median_duration:.2f}',\n",
    "    showarrow=True,\n",
    "    arrowhead=4,\n",
    "    ax=0,\n",
    "    ay=-40\n",
    ")\n",
    "\n",
    "# Update the layout if needed\n",
    "fig.update_layout(\n",
    "    title='Density Plot with Smooth Line',\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Density'\n",
    ")\n",
    "# Update the layout if needed\n",
    "fig.update_layout(title='Density Plot with Smooth Line', xaxis_title='Value', yaxis_title='Density')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conjoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
